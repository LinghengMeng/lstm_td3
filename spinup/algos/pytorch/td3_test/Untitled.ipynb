{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPCritic(nn.Module):\n",
    "    def __init__(self, obs_dim, act_dim, hidden_sizes=[256, 256]):\n",
    "        super(MLPCritic, self).__init__()\n",
    "\n",
    "        self.obs_dim = obs_dim\n",
    "        self.act_dim = act_dim\n",
    "        self.layer_sizes = [obs_dim + act_dim] + hidden_sizes + [1]\n",
    "\n",
    "        self.layers = nn.ModuleList()\n",
    "        # Hidden layers\n",
    "        for h_i in range(len(self.layer_sizes) - 2):\n",
    "            self.layers += [nn.Linear(self.layer_sizes[h_i], self.layer_sizes[h_i + 1]),\n",
    "                            nn.Sigmoid()]\n",
    "        # Output layer\n",
    "        self.layers += [nn.Linear(self.layer_sizes[-2], self.layer_sizes[-1]),\n",
    "                        nn.Identity()]\n",
    "\n",
    "    def forward(self, obs, act):\n",
    "        x = torch.cat([obs, act], dim=-1)\n",
    "        hid_activation = []\n",
    "        # Hidden layers\n",
    "        for h_i in range(len(self.layers) - 2):\n",
    "            print(self.layers[h_i])\n",
    "            x = self.layers[h_i](x)\n",
    "            # Store activation\n",
    "            if h_i % 2 == 1:\n",
    "                hid_activation.append(x)\n",
    "        # Output layer\n",
    "        x = self.layers[-2](x)\n",
    "        x = self.layers[-1](x)\n",
    "        return torch.squeeze(x, -1), hid_activation\n",
    "\n",
    "\n",
    "class MLPActor(nn.Module):\n",
    "    def __init__(self, obs_dim, act_dim, act_limit, hidden_sizes=[256, 256]):\n",
    "        super(MLPActor, self).__init__()\n",
    "        self.obs_dim = obs_dim\n",
    "        self.act_dim = act_dim\n",
    "        self.act_limit = act_limit\n",
    "        self.layer_sizes = [obs_dim] + hidden_sizes + [act_dim]\n",
    "\n",
    "        self.layers = nn.ModuleList()\n",
    "        # Hidden layers\n",
    "        for h_i in range(len(self.layer_sizes) - 2):\n",
    "            self.layers += [nn.Linear(self.layer_sizes[h_i], self.layer_sizes[h_i + 1]),\n",
    "                            nn.Sigmoid()]\n",
    "        # Output layer\n",
    "        self.layers += [nn.Linear(self.layer_sizes[-2], self.layer_sizes[-1]),\n",
    "                        nn.Tanh()]\n",
    "\n",
    "    def forward(self, obs):\n",
    "        x = obs\n",
    "        hid_activation = []\n",
    "        # Hidden layers\n",
    "        for h_i in range(len(self.layers) - 2):\n",
    "            \n",
    "            x = self.layers[h_i](x)\n",
    "            # Store activation\n",
    "            if h_i % 2 == 1:\n",
    "                hid_activation.append(x)\n",
    "        # Output layer\n",
    "        x = self.layers[-2](x)\n",
    "        x = self.layers[-1](x)\n",
    "        return self.act_limit * x, hid_activation\n",
    "\n",
    "\n",
    "class MLPActorCritic(nn.Module):\n",
    "    def __init__(self, obs_dim, act_dim, act_limit, critic_hidden_sizes=[256, 256], actor_hidden_sizes=[256, 256]):\n",
    "        super(MLPActorCritic, self).__init__()\n",
    "        self.q1 = MLPCritic(obs_dim, act_dim, critic_hidden_sizes)\n",
    "        self.q2 = MLPCritic(obs_dim, act_dim, critic_hidden_sizes)\n",
    "        self.pi = MLPActor(obs_dim, act_dim, act_limit, actor_hidden_sizes)\n",
    "\n",
    "    def act(self, obs):\n",
    "        with torch.no_grad():\n",
    "            a, _ = self.pi(obs)\n",
    "            return a.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_dim = 15\n",
    "act_dim = 5\n",
    "act_limit = 1\n",
    "critic = MLPCritic(obs_dim, act_dim)\n",
    "actor = MLPActor(obs_dim, act_dim, act_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=20, out_features=256, bias=True)\n",
      "Sigmoid()\n",
      "Linear(in_features=256, out_features=256, bias=True)\n",
      "Sigmoid()\n"
     ]
    }
   ],
   "source": [
    "m = 100\n",
    "obs = torch.as_tensor(np.random.rand(m, obs_dim), dtype=torch.float32)\n",
    "act = torch.as_tensor(np.random.rand(m, act_dim), dtype=torch.float32)\n",
    "q, q_hid_activation = critic(obs, act)\n",
    "a, a_hid_activation = actor(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None tensor([[ 0.0531, -0.1832,  0.0334,  ..., -0.2100, -0.1570, -0.0378],\n",
      "        [-0.0560, -0.1791, -0.1595,  ...,  0.1052,  0.0930,  0.0297],\n",
      "        [ 0.0045, -0.0834, -0.1346,  ...,  0.1215, -0.0272, -0.1203],\n",
      "        ...,\n",
      "        [ 0.1842, -0.1546, -0.0197,  ..., -0.0616,  0.0538, -0.0298],\n",
      "        [-0.1351, -0.1441,  0.2059,  ..., -0.1177, -0.0467,  0.1636],\n",
      "        [-0.0337,  0.1200,  0.0375,  ..., -0.1362, -0.1893,  0.0973]])\n",
      "None tensor([ 0.0584,  0.1826,  0.1727,  0.0309,  0.0184, -0.0012,  0.2171,  0.0029,\n",
      "        -0.1473,  0.1677,  0.0464,  0.1544,  0.1863,  0.1003, -0.2109,  0.1163,\n",
      "         0.1077, -0.1256, -0.0921, -0.0257, -0.2108, -0.1411,  0.2233, -0.0551,\n",
      "        -0.2153, -0.0741,  0.0124, -0.1674,  0.0214, -0.1084,  0.0072,  0.0530,\n",
      "        -0.1234, -0.0430,  0.1154, -0.1921,  0.0752,  0.1646, -0.2199, -0.0754,\n",
      "        -0.0467, -0.1953,  0.0834,  0.0946, -0.1838,  0.0632,  0.0740, -0.1502,\n",
      "        -0.1853,  0.1969, -0.0155, -0.1755, -0.1736, -0.0732,  0.1368,  0.0303,\n",
      "         0.2119,  0.1543, -0.0365, -0.1865,  0.0073,  0.1589,  0.1113,  0.1653,\n",
      "         0.0560,  0.0123,  0.1543, -0.0788,  0.0986, -0.2226,  0.1661, -0.0060,\n",
      "        -0.1474, -0.0556,  0.1001,  0.0067, -0.0806,  0.1558,  0.1296, -0.1402,\n",
      "        -0.1078, -0.1386,  0.1164,  0.1779, -0.1169, -0.0034, -0.0751, -0.0788,\n",
      "        -0.0378, -0.1992,  0.0746, -0.1919,  0.1947,  0.0840,  0.0284,  0.2157,\n",
      "        -0.2166, -0.1219,  0.1455, -0.0205,  0.0167, -0.1434, -0.1297,  0.2122,\n",
      "         0.0776, -0.1960,  0.0629, -0.0643, -0.1997, -0.0267, -0.1237, -0.2102,\n",
      "         0.1058,  0.1105,  0.1196, -0.1044,  0.0648,  0.1117, -0.1397,  0.0160,\n",
      "         0.0923,  0.1361,  0.1194, -0.1157,  0.0383,  0.1624, -0.0428,  0.1324,\n",
      "        -0.1478,  0.2230,  0.1931, -0.2038, -0.0600,  0.1950, -0.2153, -0.1685,\n",
      "         0.0902,  0.2215, -0.0177, -0.1094, -0.1774, -0.0038, -0.0213, -0.1634,\n",
      "         0.2160,  0.2154, -0.0457,  0.1931,  0.0581, -0.0151,  0.0072, -0.1321,\n",
      "        -0.1849, -0.0580,  0.0933,  0.1036, -0.1737,  0.0572, -0.0217,  0.1423,\n",
      "        -0.0647, -0.0063, -0.0334, -0.2057,  0.0876,  0.0376, -0.1239, -0.0134,\n",
      "         0.0763,  0.0111, -0.1465, -0.0234,  0.0897, -0.1581,  0.0323,  0.0973,\n",
      "        -0.0153, -0.0105,  0.0201,  0.0663, -0.0728, -0.2221,  0.1119,  0.2176,\n",
      "         0.2098,  0.0308,  0.1466, -0.1158, -0.0050, -0.0602, -0.1914, -0.1631,\n",
      "         0.2130,  0.0762, -0.0594,  0.1857,  0.0831,  0.1455, -0.0797,  0.0436,\n",
      "        -0.1016,  0.0992, -0.0904, -0.1590,  0.1970, -0.1380,  0.0022,  0.1038,\n",
      "        -0.2151,  0.1504, -0.0328, -0.1419, -0.0429,  0.2118,  0.1312,  0.0755,\n",
      "        -0.1525, -0.1557,  0.2010,  0.1386, -0.2110, -0.1951,  0.0432, -0.2225,\n",
      "        -0.0729, -0.0686, -0.1181, -0.0070,  0.2044, -0.0673,  0.0942,  0.1865,\n",
      "         0.0842, -0.1901,  0.2217,  0.0259, -0.1245,  0.2086, -0.0607, -0.1121,\n",
      "         0.1313,  0.0964, -0.1506, -0.1144, -0.1938,  0.0596, -0.1914,  0.1423,\n",
      "         0.1552,  0.1227, -0.1514, -0.1985,  0.1642,  0.0726, -0.1689, -0.0409])\n",
      "None tensor([[-0.0557, -0.0166, -0.0377,  ...,  0.0517,  0.0217, -0.0160],\n",
      "        [-0.0541,  0.0530,  0.0147,  ..., -0.0094, -0.0489, -0.0482],\n",
      "        [ 0.0468,  0.0545,  0.0419,  ..., -0.0460, -0.0517, -0.0415],\n",
      "        ...,\n",
      "        [-0.0611,  0.0014,  0.0459,  ...,  0.0388,  0.0212, -0.0072],\n",
      "        [-0.0167, -0.0340, -0.0101,  ...,  0.0488, -0.0383, -0.0185],\n",
      "        [ 0.0566, -0.0615,  0.0187,  ...,  0.0282, -0.0134,  0.0322]])\n",
      "None tensor([ 8.8981e-03,  4.5371e-03, -5.9500e-02,  1.3211e-02, -5.6107e-02,\n",
      "         3.7334e-02,  3.0637e-02,  6.4017e-03, -1.5230e-02,  4.5005e-02,\n",
      "         5.7931e-02, -6.6991e-03, -4.5223e-02,  5.2287e-02, -4.4054e-03,\n",
      "         3.5130e-02, -2.8086e-02, -5.2782e-02,  3.3455e-02, -6.0085e-02,\n",
      "        -2.1261e-03,  3.9832e-02,  5.9246e-02,  1.3202e-03, -3.0416e-02,\n",
      "         1.5514e-02,  2.9138e-02, -5.8605e-02, -6.6255e-03, -4.4164e-02,\n",
      "        -3.3489e-02,  2.1012e-02, -4.7291e-02, -6.9729e-03, -1.8332e-03,\n",
      "         1.6431e-02,  4.5576e-02,  2.3929e-02, -2.0125e-02,  4.9076e-02,\n",
      "        -8.8023e-04, -5.8845e-04, -5.6807e-02,  3.1566e-02, -3.7338e-02,\n",
      "         5.9093e-02,  4.1686e-02,  3.0088e-02, -9.1614e-03,  2.4961e-02,\n",
      "        -1.4757e-03, -9.4519e-03, -3.8566e-02, -2.0955e-02, -1.8935e-02,\n",
      "        -1.3735e-02,  5.7351e-02, -8.4447e-03,  4.8698e-02, -5.4687e-02,\n",
      "         1.8799e-04, -4.0228e-02,  3.0752e-02, -5.8500e-02,  3.4179e-02,\n",
      "        -5.4997e-02,  5.8915e-02, -6.7775e-03,  4.2260e-02,  1.9088e-02,\n",
      "        -4.2733e-02, -1.9934e-02,  2.2669e-02, -3.6335e-02, -5.6567e-02,\n",
      "         4.4866e-02,  6.4908e-03, -2.1394e-02, -3.8373e-02, -1.8850e-02,\n",
      "        -1.8753e-02,  3.0438e-02,  9.0206e-03, -8.8128e-03, -5.6710e-02,\n",
      "        -1.1680e-02, -2.7267e-02, -4.0264e-02,  5.6245e-02, -4.5247e-02,\n",
      "         4.9261e-02, -4.6482e-02,  9.4225e-03, -2.0665e-02, -2.7898e-02,\n",
      "        -1.0313e-02, -3.7877e-02,  1.8860e-02,  1.3421e-02,  4.9925e-02,\n",
      "        -4.6213e-02,  3.2177e-02,  1.7396e-02,  3.2658e-02,  5.2982e-02,\n",
      "        -1.9062e-02, -6.0771e-02,  4.4843e-03,  4.0452e-02, -3.2467e-02,\n",
      "        -5.4634e-02,  1.2208e-02, -5.8698e-02,  3.4442e-02, -1.8860e-02,\n",
      "        -1.0107e-02, -6.0533e-02, -4.1900e-02, -4.7609e-02,  6.0456e-03,\n",
      "         5.9383e-03,  1.5977e-02, -1.2764e-02,  5.4941e-02,  2.8434e-02,\n",
      "        -4.4148e-02, -3.2707e-02,  1.4123e-02,  1.4378e-02,  1.7371e-02,\n",
      "        -1.4781e-02,  3.1299e-02, -4.0373e-02, -4.7021e-02, -1.9479e-03,\n",
      "        -2.6240e-02, -2.4612e-02,  5.5505e-02,  3.4748e-02, -8.5288e-04,\n",
      "        -5.4008e-02,  2.6966e-02,  4.3621e-02, -4.3876e-03,  2.3055e-02,\n",
      "         1.9127e-02,  2.0655e-02,  9.9152e-03, -2.4639e-02,  5.4691e-02,\n",
      "        -2.5813e-02,  8.4845e-03, -3.4321e-02,  3.8818e-02,  5.5073e-02,\n",
      "        -5.9989e-03, -3.8164e-02, -4.2762e-02,  3.8188e-02,  1.2976e-02,\n",
      "        -3.0125e-02,  2.9756e-02, -1.9447e-02, -5.5036e-02, -2.2022e-02,\n",
      "         2.7255e-02,  9.7334e-03,  2.0838e-02, -6.1999e-02, -8.2498e-03,\n",
      "         5.1994e-02, -4.3037e-02,  1.4237e-02, -2.9226e-02,  5.5900e-02,\n",
      "        -2.5723e-02,  5.1914e-02, -3.9357e-02, -4.6777e-02,  3.8091e-02,\n",
      "         2.2767e-02,  6.6606e-03,  3.3521e-02, -3.5153e-03,  4.1137e-02,\n",
      "         4.7888e-03, -5.5886e-02,  4.2223e-02, -1.8863e-02,  6.8452e-03,\n",
      "         3.4575e-02, -5.2650e-02,  1.9268e-02, -4.4673e-02, -1.8988e-02,\n",
      "         2.5739e-02,  1.5694e-02, -4.0048e-02,  3.5058e-02,  3.5272e-02,\n",
      "         5.9917e-02, -2.7570e-02,  5.8054e-03, -4.1798e-02,  5.8037e-02,\n",
      "         4.9510e-02,  6.3565e-03, -6.1995e-02, -4.8213e-02, -5.1281e-02,\n",
      "        -2.5361e-02,  5.2006e-02, -5.8755e-02,  7.8163e-03,  4.3702e-02,\n",
      "         1.2664e-02, -4.0300e-02, -4.2219e-02,  3.0070e-02,  4.2722e-02,\n",
      "        -4.7317e-02,  2.5143e-02,  5.2283e-02,  3.6228e-02,  3.4936e-02,\n",
      "        -2.1142e-02,  2.3033e-02, -7.0572e-05,  5.6132e-02,  8.8530e-03,\n",
      "        -4.7686e-02, -1.8730e-02,  3.9849e-02,  2.8934e-02,  3.9660e-02,\n",
      "        -3.7427e-02, -4.9712e-02,  4.1763e-02,  3.3498e-02, -5.9875e-02,\n",
      "         7.1580e-03,  2.9321e-02,  5.4051e-02,  3.9274e-02, -2.0339e-02,\n",
      "        -6.2098e-02,  4.6815e-02,  3.2495e-02, -5.4283e-02,  3.3647e-02,\n",
      "        -5.6292e-02,  2.7239e-02, -1.4673e-02, -1.1384e-02,  5.6908e-03,\n",
      "        -5.1808e-02])\n",
      "None tensor([[-0.0612,  0.0568,  0.0047, -0.0155,  0.0139,  0.0131, -0.0185,  0.0217,\n",
      "          0.0566, -0.0593,  0.0606,  0.0477,  0.0426,  0.0610,  0.0538,  0.0353,\n",
      "         -0.0267,  0.0177, -0.0594, -0.0055, -0.0291,  0.0448,  0.0088, -0.0091,\n",
      "         -0.0335, -0.0620,  0.0376, -0.0017,  0.0197,  0.0211, -0.0499,  0.0245,\n",
      "          0.0592,  0.0508, -0.0337, -0.0115, -0.0466,  0.0265, -0.0435,  0.0277,\n",
      "          0.0519,  0.0591, -0.0377, -0.0166, -0.0110,  0.0004, -0.0153,  0.0529,\n",
      "         -0.0076, -0.0427,  0.0025,  0.0358, -0.0050,  0.0043,  0.0278, -0.0090,\n",
      "          0.0054, -0.0066,  0.0349, -0.0107, -0.0229, -0.0368,  0.0268,  0.0476,\n",
      "         -0.0075, -0.0381,  0.0186, -0.0047, -0.0292,  0.0601, -0.0276,  0.0443,\n",
      "         -0.0063,  0.0519, -0.0295, -0.0048, -0.0059,  0.0175, -0.0401, -0.0096,\n",
      "         -0.0230,  0.0426, -0.0329, -0.0576, -0.0038,  0.0282, -0.0152,  0.0251,\n",
      "         -0.0360, -0.0063, -0.0361,  0.0505, -0.0057,  0.0448, -0.0554, -0.0583,\n",
      "          0.0356, -0.0184,  0.0526, -0.0483,  0.0089, -0.0160,  0.0143, -0.0008,\n",
      "          0.0218, -0.0318,  0.0117,  0.0406, -0.0085, -0.0346,  0.0155, -0.0614,\n",
      "         -0.0564, -0.0053, -0.0024, -0.0064, -0.0581,  0.0106,  0.0195, -0.0464,\n",
      "         -0.0247, -0.0032,  0.0130, -0.0178, -0.0333, -0.0352, -0.0279, -0.0226,\n",
      "          0.0545, -0.0082, -0.0364, -0.0223, -0.0001, -0.0380,  0.0427,  0.0157,\n",
      "         -0.0424,  0.0247, -0.0411,  0.0322,  0.0353, -0.0328,  0.0017,  0.0559,\n",
      "          0.0356, -0.0262, -0.0571,  0.0329, -0.0279, -0.0376,  0.0036, -0.0176,\n",
      "          0.0364,  0.0492,  0.0609,  0.0282, -0.0208, -0.0371,  0.0582,  0.0481,\n",
      "         -0.0396,  0.0562,  0.0113,  0.0563, -0.0517,  0.0038, -0.0513, -0.0483,\n",
      "         -0.0298, -0.0101,  0.0125,  0.0255,  0.0176, -0.0354, -0.0459,  0.0035,\n",
      "          0.0164, -0.0162, -0.0492,  0.0201, -0.0156,  0.0229,  0.0318,  0.0236,\n",
      "         -0.0070,  0.0553,  0.0600,  0.0034, -0.0342,  0.0012,  0.0422, -0.0005,\n",
      "         -0.0265,  0.0083, -0.0158,  0.0076,  0.0490,  0.0064,  0.0247,  0.0324,\n",
      "         -0.0351,  0.0330, -0.0301,  0.0545, -0.0072,  0.0596,  0.0273,  0.0312,\n",
      "         -0.0286, -0.0579,  0.0468,  0.0264,  0.0168, -0.0312, -0.0346,  0.0550,\n",
      "         -0.0448, -0.0316, -0.0310, -0.0456,  0.0364,  0.0270, -0.0144,  0.0291,\n",
      "         -0.0312, -0.0390,  0.0434,  0.0494, -0.0285,  0.0150, -0.0213,  0.0130,\n",
      "          0.0144, -0.0125, -0.0174, -0.0319, -0.0499,  0.0531,  0.0275, -0.0062,\n",
      "         -0.0171, -0.0562,  0.0389, -0.0623,  0.0484,  0.0025,  0.0080,  0.0189,\n",
      "          0.0200,  0.0541, -0.0439, -0.0366, -0.0027,  0.0520,  0.0256, -0.0549]])\n",
      "None tensor([0.0416])\n"
     ]
    }
   ],
   "source": [
    "critic.parameters()\n",
    "for p in critic.parameters():\n",
    "    if p.requires_grad:\n",
    "         print(p.name, p.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPCritic(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=20, out_features=256, bias=True)\n",
      "    (1): Sigmoid()\n",
      "    (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (3): Sigmoid()\n",
      "    (4): Linear(in_features=256, out_features=1, bias=True)\n",
      "    (5): Identity()\n",
      "  )\n",
      ")\n",
      "MLPActor(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=15, out_features=256, bias=True)\n",
      "    (1): Sigmoid()\n",
      "    (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (3): Sigmoid()\n",
      "    (4): Linear(in_features=256, out_features=5, bias=True)\n",
      "    (5): Tanh()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(critic)\n",
    "print(actor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): Linear(in_features=20, out_features=256, bias=True)\n",
       "  (1): Sigmoid()\n",
       "  (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "  (3): Sigmoid()\n",
       "  (4): Linear(in_features=256, out_features=1, bias=True)\n",
       "  (5): Identity()\n",
       ")"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "critic.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6067, 0.5047, 0.4744, 0.4898, 0.5349, 0.5409, 0.4726, 0.5370, 0.4718,\n",
       "        0.3470, 0.3877, 0.5362, 0.3976, 0.5017, 0.3958, 0.5525, 0.5401, 0.3854,\n",
       "        0.5290, 0.5130, 0.4945, 0.4786, 0.5506, 0.4881, 0.5183, 0.3692, 0.6020,\n",
       "        0.3939, 0.5712, 0.5318, 0.6325, 0.5938, 0.4832, 0.5813, 0.3648, 0.4099,\n",
       "        0.5243, 0.5920, 0.5059, 0.5398, 0.3487, 0.5012, 0.5444, 0.4800, 0.6469,\n",
       "        0.4534, 0.4393, 0.5691, 0.4726, 0.5828, 0.4657, 0.5383, 0.4352, 0.3629,\n",
       "        0.5125, 0.6026, 0.4704, 0.5292, 0.4727, 0.4528, 0.4770, 0.5008, 0.4778,\n",
       "        0.5587, 0.5814, 0.5431, 0.4608, 0.6139, 0.6130, 0.4333, 0.4183, 0.3449,\n",
       "        0.6047, 0.3676, 0.5674, 0.5013, 0.5519, 0.5632, 0.4392, 0.3591, 0.4591,\n",
       "        0.5530, 0.6337, 0.3952, 0.4739, 0.4734, 0.4242, 0.4878, 0.5078, 0.6197,\n",
       "        0.4293, 0.6240, 0.4365, 0.4395, 0.5399, 0.5173, 0.6532, 0.5311, 0.3310,\n",
       "        0.5044, 0.5077, 0.3787, 0.4826, 0.5108, 0.5040, 0.4619, 0.4056, 0.5470,\n",
       "        0.5123, 0.4193, 0.4274, 0.5585, 0.5530, 0.5415, 0.4294, 0.5250, 0.4798,\n",
       "        0.4987, 0.4396, 0.5413, 0.5385, 0.3953, 0.4721, 0.4219, 0.4761, 0.5150,\n",
       "        0.3520, 0.4526, 0.5221, 0.3755, 0.5088, 0.4925, 0.5041, 0.4216, 0.4788,\n",
       "        0.4176, 0.5328, 0.4441, 0.5055, 0.4924, 0.4618, 0.5756, 0.3984, 0.5846,\n",
       "        0.4427, 0.5323, 0.4980, 0.6288, 0.5909, 0.4109, 0.4983, 0.5633, 0.5660,\n",
       "        0.6074, 0.5506, 0.6260, 0.5284, 0.5682, 0.4602, 0.5431, 0.4443, 0.6455,\n",
       "        0.4491, 0.4096, 0.3754, 0.5784, 0.4714, 0.4200, 0.4550, 0.4452, 0.4208,\n",
       "        0.5103, 0.4895, 0.5513, 0.5558, 0.3808, 0.4410, 0.4900, 0.5292, 0.5107,\n",
       "        0.4629, 0.4300, 0.4647, 0.6977, 0.4475, 0.3779, 0.5011, 0.5194, 0.4926,\n",
       "        0.4154, 0.4982, 0.5212, 0.5621, 0.5026, 0.5621, 0.5496, 0.4991, 0.6226,\n",
       "        0.4655, 0.4550, 0.5231, 0.5418, 0.3942, 0.4190, 0.4918, 0.4472, 0.5137,\n",
       "        0.4124, 0.3839, 0.4899, 0.5159, 0.5607, 0.4419, 0.5665, 0.6094, 0.5040,\n",
       "        0.4541, 0.4231, 0.3712, 0.4987, 0.4766, 0.3658, 0.4791, 0.5721, 0.4626,\n",
       "        0.5343, 0.4637, 0.5998, 0.6331, 0.7062, 0.5070, 0.5296, 0.4500, 0.4036,\n",
       "        0.5226, 0.4373, 0.3884, 0.5283, 0.4427, 0.3896, 0.4418, 0.4583, 0.5276,\n",
       "        0.4409, 0.5701, 0.5850, 0.4842, 0.4923, 0.3989, 0.5400, 0.4717, 0.4866,\n",
       "        0.5631, 0.6476, 0.5651, 0.4146], grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hid_a = hid_activation[0]\n",
    "hid_a.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-89.4653, grad_fn=<KlDivBackward>)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kl_loss = nn.KLDivLoss(reduction='sum')\n",
    "kl_loss(torch.cat(hid_activation, dim=1).mean(axis=0), rho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-89.4653, grad_fn=<KlDivBackward>)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rho = torch.as_tensor(0.05, dtype=torch.float32)\n",
    "beta = 0.5\n",
    "sparsity_penalty = torch.nn.functional.kl_div(torch.cat(hid_activation, dim=1).mean(axis=0), rho, reduction='sum')\n",
    "sparsity_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-187.5761, grad_fn=<KlDivBackward>)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparsity_penalty = torch.nn.functional.kl_div(rho, torch.cat(hid_activation, dim=1).mean(axis=0), reduction='sum')\n",
    "sparsity_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.5966)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.functional.kl_div(torch.as_tensor(0.5, dtype=torch.float32), torch.as_tensor(0.5, dtype=torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(nan)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "rho_hat = torch.as_tensor(0.5, dtype=torch.float32)\n",
    "rho = torch.ones(rho_hat.shape)\n",
    "torch.sum(rho * torch.log(rho/rho_hat) + (1 - rho) * torch.log((1 - rho)/(1 - rho_hat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rho_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(258.0015, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rho_hat = torch.cat(hid_activation, dim=1).mean(axis=0)\n",
    "rho_hat.shape\n",
    "rho = torch.ones(rho_hat.shape)*0.05\n",
    "torch.sum(rho * torch.log(rho/rho_hat) + (1 - rho) * torch.log((1 - rho)/(1 - rho_hat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
